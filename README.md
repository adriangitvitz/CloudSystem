## Job requirements

* 3+ years of experience in software engineering.
* Design and operational experience with large scale production grade systems.
* Deep experience in one or more of the following: Python, Java, Ruby, Golang, JavaScript, or shell scripting.
* Good Linux skills and understanding of operating systems.
* Experience building and maintaining large distributed systems on one of the major cloud providers (AWS, Azure, GCP).
* Extensive API design and development experience.
* Strong technical accomplishments in SQL, ETLs and data analysis skills.
* MySQL, Postgres, Redshift, or similar data handling experience.
* Experience with infrastructure as code tooling such as Terraform & CloudFormation.
* Ability to work in a fast paced, agile development environment.
* Ability to partner with business units, product management, program management and cross-functional teams to deliver business results with agility and high quality.
* Excellent time management skills and ability to work on concurrent assignments with different priorities.
* Proven results-oriented engineer with a focus on the customer and delivering quality products.
* We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don't hesitate to apply.

## Project

**1. Cloud-based Distributed Data Processing System:**

Design and implement a distributed data processing system using AWS, Azure, or GCP.
This system should be able to process large volumes of data efficiently. You could use AWS Lambda, Google Cloud Functions,
or Azure Functions for serverless computing, and AWS S3, Google Cloud Storage, or Azure Blob Storage for data storage.
Implement your system with Infrastructure as Code using Terraform or CloudFormation. Use one of the required programming
languages (Python, Java, Ruby, Golang, or JavaScript) to write the business logic.
